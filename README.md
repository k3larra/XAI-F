# More Sanity Checks for Saliency Maps supplemental material.
The basic idea for the paper was to compare what humans find important in an image to what five models trained on ResNet1k find important.
We built a web tool that was used by 5 + 25 humans to create saliency maps for three selected images (Afican camel, gorilla and toucan). 
The human salience maps were then compared to saliency maps created by five ML models. 
All code for this, for the exception of the web tool, can be found [here](Code_More_Sanity_Checks_for_Saliency_Maps.ipynb)
[a relative link](other_file.md)



<img width="517" alt="marking_process" src="https://user-images.githubusercontent.com/477262/173865707-ef3ae42e-645c-4b91-9e99-6991b800445b.png">
